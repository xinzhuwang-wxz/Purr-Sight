"""
Training Speed Monitoring Callback

ç›‘æ§è®­ç»ƒé€Ÿåº¦ï¼Œè®°å½•æ¯ä¸ªbatchçš„æ•°æ®åŠ è½½æ—¶é—´ã€å‰å‘ä¼ æ’­æ—¶é—´ã€åå‘ä¼ æ’­æ—¶é—´ç­‰ã€‚

ä½¿ç”¨æ–¹æ³•:
    åœ¨Trainerçš„callbacksä¸­æ·»åŠ SpeedMonitorå®ä¾‹
"""

import time
from typing import Dict, List
import pytorch_lightning as pl
from pytorch_lightning.callbacks import Callback

from purrsight.utils.logging import logger


class SpeedMonitor(Callback):
    """
    è®­ç»ƒé€Ÿåº¦ç›‘æ§å›è°ƒ
    
    è®°å½•ï¼š
    - æ•°æ®åŠ è½½æ—¶é—´ï¼ˆDataLoaderè¿­ä»£æ—¶é—´ï¼‰
    - å‰å‘ä¼ æ’­æ—¶é—´
    - åå‘ä¼ æ’­æ—¶é—´
    - æ€»batchæ—¶é—´
    - è®­ç»ƒé€Ÿåº¦ï¼ˆsamples/secï¼‰
    """
    
    def __init__(self, log_every_n_batches: int = 50, max_history: int = 1000):
        """
        åˆå§‹åŒ–é€Ÿåº¦ç›‘æ§å™¨
        
        Args:
            log_every_n_batches: æ¯Nä¸ªbatchè®°å½•ä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯
            max_history: ä¿ç•™çš„æœ€å¤§å†å²è®°å½•æ•°ï¼Œè¶…è¿‡åè‡ªåŠ¨æ¸…ç†ï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
        """
        super().__init__()
        self.log_every_n_batches = log_every_n_batches
        self.max_history = max_history  # ğŸ”§ ä¿®å¤ï¼šé™åˆ¶å†å²è®°å½•æ•°é‡ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
        self.batch_times: List[float] = []
        self.data_load_times: List[float] = []
        self.forward_times: List[float] = []
        self.backward_times: List[float] = []
        
        # ğŸ”§ ä¼˜åŒ–ï¼šæ·»åŠ éªŒè¯é˜¶æ®µæ€§èƒ½ç›‘æ§
        self.val_batch_times: List[float] = []
        self.val_metrics_times: List[float] = []
        
        # ç”¨äºæµ‹é‡æ—¶é—´
        self._batch_start_time: float = None
        self._data_load_end_time: float = None
        self._forward_end_time: float = None
        self._val_batch_start_time: float = None
        self._val_metrics_start_time: float = None
    
    def on_train_batch_start(self, trainer, pl_module, batch, batch_idx):
        """è®°å½•batchå¼€å§‹æ—¶é—´"""
        self._batch_start_time = time.time()
    
    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):
        """è®°å½•batchç»“æŸæ—¶é—´å¹¶è®¡ç®—å„é¡¹è€—æ—¶"""
        batch_end_time = time.time()
        
        if self._batch_start_time is not None:
            total_time = batch_end_time - self._batch_start_time
            self.batch_times.append(total_time)
            
            # ğŸ”§ ä¿®å¤ï¼šé˜²æ­¢å†…å­˜æ³„æ¼ï¼Œé™åˆ¶å†å²è®°å½•æ•°é‡
            if len(self.batch_times) > self.max_history:
                # åªä¿ç•™æœ€è¿‘çš„max_historyæ¡è®°å½•
                self.batch_times = self.batch_times[-self.max_history:]
            
            # ä¼°ç®—å„é¡¹æ—¶é—´ï¼ˆLightningä¸ç›´æ¥æä¾›ï¼Œæˆ‘ä»¬é€šè¿‡å·®å€¼ä¼°ç®—ï¼‰
            # æ³¨æ„ï¼šè¿™æ˜¯è¿‘ä¼¼å€¼ï¼Œå®é™…æ—¶é—´å¯èƒ½ç•¥æœ‰åå·®
            if len(self.batch_times) > 1:
                # ä½¿ç”¨ç§»åŠ¨å¹³å‡ä¼°ç®—æ•°æ®åŠ è½½æ—¶é—´ï¼ˆå‡è®¾æ•°æ®åŠ è½½ä¸batchæ—¶é—´ç›¸å…³ï¼‰
                avg_batch_time = sum(self.batch_times[-10:]) / min(10, len(self.batch_times))
                # å‡è®¾æ•°æ®åŠ è½½å batchæ—¶é—´çš„10-30%ï¼ˆå–å†³äºnum_workersï¼‰
                estimated_data_load = avg_batch_time * 0.2
                self.data_load_times.append(estimated_data_load)
                
                # ğŸ”§ ä¿®å¤ï¼šé˜²æ­¢å†…å­˜æ³„æ¼ï¼Œé™åˆ¶data_load_timesåˆ—è¡¨å¤§å°
                if len(self.data_load_times) > self.max_history:
                    self.data_load_times = self.data_load_times[-self.max_history:]
            
            # è®°å½•åˆ°Lightning logger
            if (batch_idx + 1) % self.log_every_n_batches == 0:
                # ğŸ”§ ä¿®å¤3ï¼šä¼˜åŒ–ç§»åŠ¨å¹³å‡è®¡ç®—ï¼ˆåªåœ¨éœ€è¦æ—¶è®¡ç®—ï¼Œé¿å…é‡å¤è®¡ç®—ï¼‰
                # åªè®¡ç®—ä¸€æ¬¡ï¼Œé¿å…é‡å¤è®¡ç®—
                recent_times = self.batch_times[-self.log_every_n_batches:]
                avg_batch_time = sum(recent_times) / len(recent_times) if recent_times else 0.0
                batch_size = trainer.train_dataloader.batch_size if hasattr(trainer.train_dataloader, 'batch_size') else 1
                samples_per_sec = batch_size / avg_batch_time if avg_batch_time > 0 else 0
                
                pl_module.log("train/batch_time_avg", avg_batch_time, on_step=True, on_epoch=False)
                pl_module.log("train/samples_per_sec", samples_per_sec, on_step=True, on_epoch=False)
                
                logger.info(
                    f"Speed stats (batch {batch_idx + 1}): "
                    f"avg_batch_time={avg_batch_time*1000:.1f}ms, "
                    f"throughput={samples_per_sec:.1f} samples/sec"
                )
    
    def on_train_epoch_end(self, trainer, pl_module):
        """epochç»“æŸæ—¶æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        if self.batch_times:
            avg_batch_time = sum(self.batch_times) / len(self.batch_times)
            min_batch_time = min(self.batch_times)
            max_batch_time = max(self.batch_times)
            
            batch_size = trainer.train_dataloader.batch_size if hasattr(trainer.train_dataloader, 'batch_size') else 1
            avg_samples_per_sec = batch_size / avg_batch_time if avg_batch_time > 0 else 0
            
            logger.info("=" * 80)
            logger.info("Training Speed Summary (Epoch End)")
            logger.info("=" * 80)
            logger.info(f"  Average batch time: {avg_batch_time*1000:.1f} ms")
            logger.info(f"  Min batch time:      {min_batch_time*1000:.1f} ms")
            logger.info(f"  Max batch time:      {max_batch_time*1000:.1f} ms")
            logger.info(f"  Average throughput: {avg_samples_per_sec:.1f} samples/sec")
            logger.info("=" * 80)
            
            # è®°å½•åˆ°Lightning logger
            pl_module.log("train/batch_time_avg_epoch", avg_batch_time, on_step=False, on_epoch=True)
            pl_module.log("train/samples_per_sec_avg_epoch", avg_samples_per_sec, on_step=False, on_epoch=True)
            
            # ğŸ”§ ä¿®å¤ï¼šepochç»“æŸåæ¸…ç†å†å²è®°å½•ï¼Œé‡Šæ”¾å†…å­˜ï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
            self.batch_times.clear()
            self.data_load_times.clear()
            self.forward_times.clear()
            self.backward_times.clear()
    
    def on_validation_batch_start(self, trainer, pl_module, batch, batch_idx):
        """è®°å½•validation batchå¼€å§‹æ—¶é—´"""
        self._val_batch_start_time = time.time()
    
    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):
        """è®°å½•validation batchç»“æŸæ—¶é—´"""
        batch_end_time = time.time()
        
        if self._val_batch_start_time is not None:
            total_time = batch_end_time - self._val_batch_start_time
            self.val_batch_times.append(total_time)
            
            # ğŸ”§ ä¼˜åŒ–ï¼šé˜²æ­¢å†…å­˜æ³„æ¼ï¼Œé™åˆ¶å†å²è®°å½•æ•°é‡
            if len(self.val_batch_times) > self.max_history:
                self.val_batch_times = self.val_batch_times[-self.max_history:]
            
            # è®°å½•éªŒè¯batchæ—¶é—´ï¼ˆæ¯Nä¸ªbatchè®°å½•ä¸€æ¬¡ï¼‰
            if (batch_idx + 1) % self.log_every_n_batches == 0:
                avg_val_time = sum(self.val_batch_times[-self.log_every_n_batches:]) / min(self.log_every_n_batches, len(self.val_batch_times))
                logger.info(f"Validation batch {batch_idx + 1} time: {total_time*1000:.1f}ms (avg: {avg_val_time*1000:.1f}ms)")
    
    def on_validation_epoch_end(self, trainer, pl_module):
        """éªŒè¯epochç»“æŸæ—¶æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        if self.val_batch_times:
            avg_val_time = sum(self.val_batch_times) / len(self.val_batch_times)
            min_val_time = min(self.val_batch_times)
            max_val_time = max(self.val_batch_times)
            
            batch_size = trainer.val_dataloaders[0].batch_size if hasattr(trainer, 'val_dataloaders') and trainer.val_dataloaders else 1
            avg_samples_per_sec = batch_size / avg_val_time if avg_val_time > 0 else 0
            
            logger.info("=" * 80)
            logger.info("Validation Speed Summary (Epoch End)")
            logger.info("=" * 80)
            logger.info(f"  Average batch time: {avg_val_time*1000:.1f} ms")
            logger.info(f"  Min batch time:      {min_val_time*1000:.1f} ms")
            logger.info(f"  Max batch time:      {max_val_time*1000:.1f} ms")
            logger.info(f"  Average throughput: {avg_samples_per_sec:.1f} samples/sec")
            if self.val_metrics_times:
                avg_metrics_time = sum(self.val_metrics_times) / len(self.val_metrics_times)
                logger.info(f"  Metrics computation: {avg_metrics_time*1000:.1f} ms (avg)")
            logger.info("=" * 80)
            
            # è®°å½•åˆ°Lightning logger
            pl_module.log("val/batch_time_avg_epoch", avg_val_time, on_step=False, on_epoch=True)
            pl_module.log("val/samples_per_sec_avg_epoch", avg_samples_per_sec, on_step=False, on_epoch=True)
            
            # ğŸ”§ ä¼˜åŒ–ï¼šepochç»“æŸåæ¸…ç†å†å²è®°å½•ï¼Œé‡Šæ”¾å†…å­˜ï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
            self.val_batch_times.clear()
            self.val_metrics_times.clear()
