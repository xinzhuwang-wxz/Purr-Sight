"""
Batchå¤„ç†å·¥å…·ï¼šæ”¯æŒbatchå†…ä¸åŒæ ·æœ¬æœ‰ä¸åŒçš„æ¨¡æ€ç»„åˆ

æä¾›ç»Ÿä¸€çš„batchå¤„ç†åŠŸèƒ½ï¼Œé…åˆ Preprocessor.process_batch() ä½¿ç”¨ã€‚

åŒ…å«ï¼š
- prepare_batch_features: å°†é¢„å¤„ç†è¾“å‡ºè½¬æ¢ä¸ºtensorå¹¶åˆ›å»ºsample-levelçš„modality masks

æ³¨æ„ï¼šå½“å‰è®­ç»ƒæµç¨‹ï¼ˆtrain/train_alignmentï¼‰ä¸å†ä½¿ç”¨æ­¤å‡½æ•°ã€‚
è®­ç»ƒæµç¨‹ç°åœ¨ä½¿ç”¨ï¼š
1. Dataset.__getitem__() - è¿”å›numpyæ ¼å¼å•æ ·æœ¬ç‰¹å¾
2. collate_batch() - åˆå¹¶ä¸ºbatchæ ¼å¼numpyæ•°ç»„ï¼Œåˆ›å»ºmodality_masksï¼ˆnumpyæ ¼å¼ï¼‰
3. training_step() - åœ¨GPUä¸Šè½¬æ¢ä¸ºtensorï¼ˆèŠ‚çœCPUå†…å­˜ï¼‰
4. encode_batch() - ç¼–ç ç‰¹å¾
5. forward() - å¯¹é½ç‰¹å¾

æ­¤å‡½æ•°ä¿ç•™ç”¨äºå…¶ä»–åœºæ™¯ï¼ˆæµ‹è¯•ã€å…¶ä»–è®­ç»ƒè„šæœ¬ç­‰ï¼‰ã€‚
"""

import torch
import numpy as np
from typing import Dict, Optional, Union, Tuple
from purrsight.config import FeatureKey, Modality, ModalitySource
from purrsight.utils.logging import logger


def prepare_batch_features(
    batch_features: Dict[str, np.ndarray],
    device: Optional[Union[str, torch.device]] = None,
) -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor]]:
    """
    å°†Preprocessor.process_batch()çš„è¾“å‡ºè½¬æ¢ä¸ºtensorå¹¶åˆ›å»ºsample-levelçš„modality masks
    
    âš ï¸ æ³¨æ„ï¼šå½“å‰è®­ç»ƒæµç¨‹ï¼ˆtrain/train_alignmentï¼‰ä¸å†ä½¿ç”¨æ­¤å‡½æ•°ã€‚
    è®­ç»ƒæµç¨‹ç°åœ¨ç”±collate_batch()å’Œtraining_step()å¤„ç†ï¼Œä»¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨
    ï¼ˆtensorè½¬æ¢åœ¨GPUä¸Šè¿›è¡Œï¼Œè€Œä¸æ˜¯åœ¨CPUä¸Šï¼‰ã€‚
    
    æ­¤å‡½æ•°ä¿ç•™ç”¨äºå…¶ä»–åœºæ™¯ï¼ˆæµ‹è¯•ã€å…¶ä»–è®­ç»ƒè„šæœ¬ç­‰ï¼‰ã€‚
    
    åŠŸèƒ½ï¼š
    1. å°†numpyæ•°ç»„è½¬æ¢ä¸ºPyTorch tensor
    2. åˆ›å»ºsample-levelçš„æ¨¡æ€maskï¼ˆæ¯ä¸ªæ ·æœ¬çš„æ¨¡æ€å­˜åœ¨æ ‡è®°ï¼‰
    
    Args:
        batch_features: Preprocessor.process_batch()çš„è¾“å‡ºï¼Œé”®ä¸ºFeatureKeyï¼Œå€¼ä¸ºbatchæ ¼å¼çš„numpyæ•°ç»„
            æ‰€æœ‰ç‰¹å¾å½¢çŠ¶ä¸º(B, ...)
        device: ç›®æ ‡è®¾å¤‡ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨é€‰æ‹©
    
    Returns:
        (tensor_features, modality_masks)å…ƒç»„ï¼š
        - tensor_features: è½¬æ¢åçš„ç‰¹å¾å­—å…¸ï¼Œé”®ä¸ºFeatureKeyï¼Œå€¼ä¸ºå½¢çŠ¶ä¸º(B, ...)çš„tensor
        - modality_masks: sample-levelçš„æ¨¡æ€maskå­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸ºå½¢çŠ¶ä¸º(B,)çš„bool tensor
            æ¯ä¸ªå…ƒç´ è¡¨ç¤ºå¯¹åº”æ ·æœ¬æ˜¯å¦åŒ…å«è¯¥æ¨¡æ€
    
    Example:
        >>> from purrsight.preprocess import Preprocessor
        >>> batch_inputs = [
        ...     {"text": "Cat playing", "image": "/path/to/cat1.jpg"},
        ...     {"text": "Cat sleeping"},
        ...     {"image": "/path/to/cat2.jpg"},
        ... ]
        >>> features = Preprocessor.process_batch(batch_inputs)  # numpy batchæ ¼å¼
        >>> tensor_features, masks = prepare_batch_features(features)
    """
    if len(batch_features) == 0:
        raise ValueError("batch_featuresä¸èƒ½ä¸ºç©º")
    
    # ç¡®å®šbatchå¤§å°ï¼ˆä»ç¬¬ä¸€ä¸ªç‰¹å¾æ¨æ–­ï¼‰
    batch_size = None
    for feat in batch_features.values():
        if feat is not None and feat.ndim > 0:
            batch_size = feat.shape[0]
            break
    
    if batch_size is None:
        raise ValueError("æ— æ³•ä»batch_featuresæ¨æ–­batchå¤§å°")
    
    # ç¡®å®šdevice
    if device is None:
        from purrsight.utils.tools import get_available_device
        device = get_available_device()
    if isinstance(device, str):
        device = torch.device(device)
    
    # ä»batch_featuresä¸­æå–modality_masksï¼ˆé¢„å¤„ç†é˜¶æ®µåˆ›å»ºï¼‰
    # Preprocessor.process_batch() æ€»æ˜¯åˆ›å»º _modality_masksï¼Œä½†ä¿ç•™å‘åå…¼å®¹é€»è¾‘
    if "_modality_masks" in batch_features:
        modality_masks_dict = batch_features["_modality_masks"]
        # ç§»é™¤ç‰¹æ®Šé”®ï¼Œä¸å‚ä¸åç»­å¤„ç†
        del batch_features["_modality_masks"]
        
        # ğŸ”§ ä¿®å¤ï¼šéªŒè¯maskä¸video_metadataçš„ä¸€è‡´æ€§
        video_metadata = batch_features.get("_video_metadata", {})
        if video_metadata:
            for idx_str, meta in video_metadata.items():
                idx = int(idx_str)  # ç¡®ä¿æ˜¯int
                if idx >= batch_size:
                    continue  # è·³è¿‡è¶…å‡ºbatchèŒƒå›´çš„ç´¢å¼•
                
                # å¦‚æœè§†é¢‘å¸§æå–å¤±è´¥ï¼Œç¡®ä¿IMAGE maskä¸ºFalse
                if not meta.get("image_valid", True):
                    if Modality.IMAGE.value in modality_masks_dict:
                        modality_masks_dict[Modality.IMAGE.value][idx] = False
                        logger.debug(
                            f"æ ·æœ¬{idx}: è§†é¢‘å¸§æå–å¤±è´¥ï¼ŒIMAGE maskå·²è®¾ç½®ä¸ºFalse"
                        )
                
                # å¦‚æœè§†é¢‘éŸ³é¢‘æ— æ•ˆä¸”audio_sourceæ˜¯videoï¼Œç¡®ä¿AUDIO maskä¸ºFalse
                if not meta.get("audio_valid", True):
                    audio_source = meta.get("audio_source")
                    if audio_source == ModalitySource.VIDEO.value:
                        if Modality.AUDIO.value in modality_masks_dict:
                            modality_masks_dict[Modality.AUDIO.value][idx] = False
                            logger.debug(
                                f"æ ·æœ¬{idx}: è§†é¢‘éŸ³é¢‘æ— æ•ˆä¸”source=videoï¼ŒAUDIO maskå·²è®¾ç½®ä¸ºFalse"
                            )
    else:
        # ğŸ”§ æ¸…ç†ï¼šå‘åå…¼å®¹åˆ†æ”¯ï¼ˆä¸»è¦ç”¨äºæµ‹è¯•åœºæ™¯ï¼‰
        # æ³¨æ„ï¼šå½“å‰ç‰ˆæœ¬çš„Preprocessor.process_batch()æ€»æ˜¯åˆ›å»º_modality_masks
        # æ­¤åˆ†æ”¯ä¸»è¦ç”¨äºæµ‹è¯•æˆ–ç›´æ¥è°ƒç”¨prepare_batch_featuresçš„åœºæ™¯
        logger.warning(
            "batch_featuresä¸­æœªæ‰¾åˆ°'_modality_masks'ï¼Œå°†æ ¹æ®ç‰¹å¾å€¼æ¨æ–­æ¨¡æ€å­˜åœ¨æƒ…å†µã€‚"
            "è¿™å¯èƒ½æ˜¯bugï¼Œè¯·æ£€æŸ¥é¢„å¤„ç†é€»è¾‘ã€‚å¦‚æœè¿™æ˜¯æµ‹è¯•åœºæ™¯ï¼Œå¯ä»¥å¿½ç•¥æ­¤è­¦å‘Šã€‚"
        )
        modality_masks_dict = {}
        video_metadata = batch_features.get("_video_metadata", {})

        # ç®€åŒ–æ¨æ–­ï¼šåŸºäºç‰¹å¾å­˜åœ¨æ€§å’Œvideo_metadata
        for modality in [Modality.TEXT, Modality.IMAGE, Modality.AUDIO]:
            modality_key = modality.value
            if modality == Modality.TEXT:
                has_modality = (
                    FeatureKey.TEXT in batch_features
                    and FeatureKey.TEXT_ATTENTION_MASK in batch_features
                )
                if has_modality:
                    mask = np.any(batch_features[FeatureKey.TEXT_ATTENTION_MASK] != 0, axis=1)
                else:
                    mask = np.zeros(batch_size, dtype=np.bool_)
            elif modality == Modality.IMAGE:
                has_modality = FeatureKey.IMAGE in batch_features
                if has_modality:
                    # ç®€åŒ–ï¼šæ£€æŸ¥video_metadataæˆ–ç‰¹å¾å€¼ä¸ä¸ºå…¨é›¶
                    img_feat = batch_features[FeatureKey.IMAGE]
                    
                    # å¤„ç†16å¸§æ ¼å¼å’Œå•å¸§æ ¼å¼
                    if img_feat.ndim == 5:
                        # 16å¸§æ ¼å¼ï¼š(B, 16, 3, 224, 224)
                        # Sumæ‰æ‰€æœ‰ç©ºé—´å’Œæ—¶é—´ç»´åº¦ï¼Œåªä¿ç•™batchç»´åº¦
                        img_mask = np.sum(np.abs(img_feat), axis=(1, 2, 3, 4)) > 1e-6
                    elif img_feat.ndim == 4:
                        # å•å¸§æ ¼å¼ï¼š(B, 3, 224, 224)
                        # Sumæ‰æ‰€æœ‰ç©ºé—´ç»´åº¦ï¼Œåªä¿ç•™batchç»´åº¦
                        img_mask = np.sum(np.abs(img_feat), axis=(1, 2, 3)) > 1e-6
                    else:
                        # æœªçŸ¥æ ¼å¼ï¼Œå°è¯•sumæ‰æ‰€æœ‰ébatchç»´åº¦
                        sum_axes = tuple(range(1, img_feat.ndim))
                        img_mask = np.sum(np.abs(img_feat), axis=sum_axes) > 1e-6
                    
                    if video_metadata:
                        # è§†é¢‘æ ·æœ¬æ€»æ˜¯æœ‰IMAGEï¼ˆ16å¸§ï¼‰
                        video_mask = np.array([
                            idx in video_metadata and video_metadata[idx].get("has_video", False)
                            for idx in range(batch_size)
                        ], dtype=np.bool_)
                        # åˆå¹¶ï¼šè§†é¢‘æˆ–ç‹¬ç«‹å›¾åƒ
                        mask = video_mask | img_mask
                    else:
                        mask = img_mask
                else:
                    mask = np.zeros(batch_size, dtype=np.bool_)
            elif modality == Modality.AUDIO:
                has_modality = FeatureKey.AUDIO in batch_features
                if has_modality:
                    # ä¼˜åŒ–ï¼šä½¿ç”¨æ›´é«˜æ•ˆçš„æ–¹æ³•æ£€æŸ¥éé›¶ï¼ˆé¿å…np.iscloseçš„å¼€é”€ï¼‰
                    mask = np.sum(np.abs(batch_features[FeatureKey.AUDIO]), axis=(1, 2)) > 1e-6
                else:
                    mask = np.zeros(batch_size, dtype=np.bool_)

            modality_masks_dict[modality_key] = mask.astype(np.bool_)
    
    # å°†numpy modality_masksè½¬æ¢ä¸ºtorch tensor
    # æ³¨æ„ï¼šVIDEO maskä¸å†éœ€è¦ï¼Œè§†é¢‘å·²åˆ†è§£ä¸ºIMAGEå’ŒAUDIO
    modality_masks = {}
    for modality in [Modality.TEXT, Modality.IMAGE, Modality.AUDIO]:
        modality_key = modality.value
        if modality_key in modality_masks_dict:
            mask_np = modality_masks_dict[modality_key]
            # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿mask_npæ˜¯1ç»´æ•°ç»„ï¼Œé¿å…è½¬æ¢ä¸º0ç»´tensor
            if isinstance(mask_np, np.ndarray):
                if mask_np.ndim == 0:
                    # 0ç»´æ ‡é‡ï¼Œè½¬æ¢ä¸º1ç»´æ•°ç»„
                    mask_np = np.array([mask_np.item()], dtype=np.bool_)
                elif mask_np.ndim > 1:
                    # å¤šç»´æ•°ç»„ï¼Œflattenä¸º1ç»´
                    mask_np = mask_np.flatten()
            else:
                # éæ•°ç»„ç±»å‹ï¼ˆå¦‚boolï¼‰ï¼Œè½¬æ¢ä¸º1ç»´æ•°ç»„
                mask_np = np.array([bool(mask_np)], dtype=np.bool_)
            mask = torch.from_numpy(mask_np).to(device)
            # ç¡®ä¿maskæ˜¯1ç»´çš„
            if mask.dim() == 0:
                mask = mask.unsqueeze(0)
        else:
            mask = torch.zeros(batch_size, dtype=torch.bool, device=device)
        modality_masks[modality_key] = mask
    
    # è½¬æ¢ä¸ºtensor
    tensor_features = {}
    for key, feat in batch_features.items():
        # è·³è¿‡ç‰¹æ®Šé”®ï¼ˆä¸æ˜¯numpyæ•°ç»„ï¼‰
        if key == "_video_metadata" or key == "_modality_sources":
            tensor_features[key] = feat  # ä¿ç•™metadataå­—å…¸
            continue
        
        if feat is not None:
            # ç¡®ä¿featæ˜¯numpyæ•°ç»„
            if not isinstance(feat, np.ndarray):
                # å¦‚æœä¸æ˜¯numpyæ•°ç»„ï¼Œè·³è¿‡æˆ–è®°å½•è­¦å‘Š
                continue
            
            # è½¬æ¢ä¸ºtensor
            if feat.dtype == np.int64:
                tensor_feat = torch.from_numpy(feat).long()
            elif feat.dtype == np.int32:
                tensor_feat = torch.from_numpy(feat).int()
            else:
                tensor_feat = torch.from_numpy(feat.astype(np.float32)).float()
            
            tensor_feat = tensor_feat.to(device)
            tensor_features[key] = tensor_feat
    
    return tensor_features, modality_masks
