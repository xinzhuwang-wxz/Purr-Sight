"""
å¯¹æ¯”å­¦ä¹ è¯„ä¼°æŒ‡æ ‡æ¨¡å—

æä¾›å¯¹æ¯”å­¦ä¹ ä»»åŠ¡çš„è¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…æ‹¬æ£€ç´¢æŒ‡æ ‡ã€ç›¸ä¼¼åº¦æŒ‡æ ‡å’Œå¯¹é½è´¨é‡æŒ‡æ ‡ã€‚

åŒ…å«ï¼š
- ContrastiveMetrics: å¯¹æ¯”å­¦ä¹ è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨ç±»
"""

import torch
import torch.nn.functional as F
from typing import Dict, List, Optional, Tuple
import numpy as np

from purrsight.config import Modality


class ContrastiveMetrics:
    """
    å¯¹æ¯”å­¦ä¹ è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨
    
    æä¾›å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼š
    1. Retrieval metrics: Recall@K, MRR, Median Rank
    2. Similarity metrics: Positive/Negative pair similarity
    3. Alignment quality: Cross-modal alignment score
    
    Attributes:
        k_values: Recall@Kçš„Kå€¼åˆ—è¡¨
    """
    
    def __init__(self, k_values: List[int] = [1, 5, 10]):
        """
        åˆå§‹åŒ–è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨
        
        Args:
            k_values: Recall@Kçš„Kå€¼åˆ—è¡¨ï¼Œé»˜è®¤[1, 5, 10]
        """
        self.k_values = k_values
    
    def compute_retrieval_metrics(
        self,
        query_features: torch.Tensor,
        key_features: torch.Tensor,
        mask: Optional[torch.Tensor] = None,
    ) -> Dict[str, float]:
        """
        è®¡ç®—æ£€ç´¢æŒ‡æ ‡ï¼šRecall@K, MRR, Median Rank
        
        Args:
            query_features: Queryç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(B, D)ï¼Œå·²å½’ä¸€åŒ–
            key_features: Keyç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(B, D)ï¼Œå·²å½’ä¸€åŒ–
            mask: Sample-level maskï¼Œå½¢çŠ¶ä¸º(B,)ï¼ŒTrueè¡¨ç¤ºæœ‰æ•ˆæ ·æœ¬
        
        Returns:
            åŒ…å«æ£€ç´¢æŒ‡æ ‡çš„å­—å…¸ï¼š
            - recall_at_k: Dict[int, float] - å„Kå€¼çš„Recall@K
            - mrr: float - Mean Reciprocal Rank
            - median_rank: float - Median Rank
        """
        B = query_features.shape[0]
        device = query_features.device
        
        # åº”ç”¨maskï¼ˆå¦‚æœæä¾›ï¼‰
        if mask is not None:
            if mask.shape[0] != B:
                raise ValueError(f"Maskå½¢çŠ¶ä¸åŒ¹é…ï¼šmask {mask.shape} vs batch size {B}")
            if mask.device != device:
                mask = mask.to(device)
            valid_indices = torch.where(mask)[0]
            if len(valid_indices) < 2:
                # æœ‰æ•ˆæ ·æœ¬ä¸è¶³ï¼Œè¿”å›é»˜è®¤å€¼
                return {
                    **{f"recall_at_{k}": 0.0 for k in self.k_values},
                    "mrr": 0.0,
                    "median_rank": float(B),
                }
            query_features = query_features[valid_indices]
            key_features = key_features[valid_indices]
            B = len(valid_indices)
        else:
            valid_indices = torch.arange(B, device=device)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ (B, B)
        # å¯¹è§’çº¿å…ƒç´ (i, i)æ˜¯æ­£æ ·æœ¬å¯¹
        similarity_matrix = query_features @ key_features.T  # (B, B)
        
        # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šå‘é‡åŒ–rankè®¡ç®—ï¼Œé¿å…å¾ªç¯æ’åº
        # ä¸€æ¬¡æ€§å¯¹æ‰€æœ‰è¡Œæ’åºï¼ˆO(B log B)è€Œä¸æ˜¯Bæ¬¡O(B log B)ï¼‰
        sorted_indices = torch.argsort(similarity_matrix, dim=1, descending=True)  # (B, B)
        
        # æ‰¾åˆ°æ¯ä¸ªæ­£æ ·æœ¬çš„rankï¼šsorted_indices[i, rank-1] == i
        # åˆ›å»ºç´¢å¼•çŸ©é˜µï¼šæ¯è¡Œçš„ç¬¬iåˆ—åº”è¯¥æ˜¯iï¼ˆæ­£æ ·æœ¬ä½ç½®ï¼‰
        target_indices = torch.arange(B, device=device).unsqueeze(1).expand(-1, B)  # (B, B)
        # æ‰¾åˆ°æ¯è¡Œä¸­target_indicesçš„ä½ç½®
        rank_mask = (sorted_indices == target_indices)  # (B, B)ï¼Œæ¯è¡Œåªæœ‰ä¸€ä¸ªTrue
        ranks = rank_mask.nonzero(as_tuple=True)[1] + 1  # rankä»1å¼€å§‹
        ranks = ranks.cpu().numpy()  # è½¬æ¢ä¸ºnumpyæ•°ç»„
        
        # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨numpyæ‰¹é‡è®¡ç®—ï¼Œé¿å…å¤šæ¬¡.item()è°ƒç”¨
        # è®¡ç®—Recall@K
        recall_at_k = {}
        for k in self.k_values:
            recall_at_k[f"recall_at_{k}"] = float((ranks <= k).mean())
        
        # è®¡ç®—MRR (Mean Reciprocal Rank)
        reciprocal_ranks = 1.0 / ranks
        mrr = float(reciprocal_ranks.mean())
        
        # è®¡ç®—Median Rank
        median_rank = float(np.median(ranks))
        
        return {
            **recall_at_k,
            "mrr": mrr,
            "median_rank": median_rank,
        }
    
    def compute_similarity_metrics(
        self,
        query_features: torch.Tensor,
        key_features: torch.Tensor,
        mask: Optional[torch.Tensor] = None,
    ) -> Dict[str, float]:
        """
        è®¡ç®—ç›¸ä¼¼åº¦æŒ‡æ ‡ï¼šæ­£æ ·æœ¬å¯¹å’Œè´Ÿæ ·æœ¬å¯¹çš„å¹³å‡ç›¸ä¼¼åº¦
        
        Args:
            query_features: Queryç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(B, D)ï¼Œå·²å½’ä¸€åŒ–
            key_features: Keyç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(B, D)ï¼Œå·²å½’ä¸€åŒ–
            mask: Sample-level maskï¼Œå½¢çŠ¶ä¸º(B,)ï¼ŒTrueè¡¨ç¤ºæœ‰æ•ˆæ ·æœ¬
        
        Returns:
            åŒ…å«ç›¸ä¼¼åº¦æŒ‡æ ‡çš„å­—å…¸ï¼š
            - positive_similarity: float - æ­£æ ·æœ¬å¯¹çš„å¹³å‡ç›¸ä¼¼åº¦
            - negative_similarity: float - è´Ÿæ ·æœ¬å¯¹çš„å¹³å‡ç›¸ä¼¼åº¦
            - similarity_gap: float - æ­£è´Ÿæ ·æœ¬ç›¸ä¼¼åº¦å·®è·
        """
        B = query_features.shape[0]
        device = query_features.device
        
        # åº”ç”¨maskï¼ˆå¦‚æœæä¾›ï¼‰
        if mask is not None:
            if mask.shape[0] != B:
                raise ValueError(f"Maskå½¢çŠ¶ä¸åŒ¹é…ï¼šmask {mask.shape} vs batch size {B}")
            if mask.device != device:
                mask = mask.to(device)
            valid_indices = torch.where(mask)[0]
            if len(valid_indices) < 2:
                return {
                    "positive_similarity": 0.0,
                    "negative_similarity": 0.0,
                    "similarity_gap": 0.0,
                }
            query_features = query_features[valid_indices]
            key_features = key_features[valid_indices]
            B = len(valid_indices)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ (B, B)
        similarity_matrix = query_features @ key_features.T  # (B, B)
        
        # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šæ‰¹é‡è®¡ç®—åå†è°ƒç”¨.item()ï¼Œå‡å°‘CPU-GPUåŒæ­¥
        # æ­£æ ·æœ¬å¯¹ï¼šå¯¹è§’çº¿å…ƒç´ 
        positive_similarities = torch.diag(similarity_matrix)  # (B,)
        positive_similarity = positive_similarities.mean().item()
        
        # è´Ÿæ ·æœ¬å¯¹ï¼šéå¯¹è§’çº¿å…ƒç´ 
        # åˆ›å»ºmaskï¼Œæ’é™¤å¯¹è§’çº¿
        mask_matrix = ~torch.eye(B, dtype=torch.bool, device=device)
        negative_similarities = similarity_matrix[mask_matrix]  # (B*(B-1),)
        negative_similarity = negative_similarities.mean().item()
        
        # ç›¸ä¼¼åº¦å·®è·ï¼ˆåœ¨CPUä¸Šè®¡ç®—ï¼Œé¿å…GPU-CPUåŒæ­¥ï¼‰
        similarity_gap = positive_similarity - negative_similarity
        
        return {
            "positive_similarity": positive_similarity,
            "negative_similarity": negative_similarity,
            "similarity_gap": similarity_gap,
        }
    
    def compute_alignment_score(
        self,
        features: Dict[str, torch.Tensor],
        modality_masks: Optional[Dict[str, torch.Tensor]] = None,
    ) -> Dict[str, float]:
        """
        è®¡ç®—å¯¹é½è´¨é‡æŒ‡æ ‡ï¼šè·¨æ¨¡æ€å¯¹é½åˆ†æ•°
        
        å¯¹äºæ¯ä¸ªæ¨¡æ€å¯¹ï¼Œè®¡ç®—ï¼š
        1. æ£€ç´¢æŒ‡æ ‡ï¼ˆRecall@K, MRRï¼‰
        2. ç›¸ä¼¼åº¦æŒ‡æ ‡ï¼ˆæ­£è´Ÿæ ·æœ¬ç›¸ä¼¼åº¦å·®è·ï¼‰
        
        Args:
            features: å¯¹é½åçš„ç‰¹å¾å­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸º(B, D)çš„tensor
            modality_masks: æ¨¡æ€maskå­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸º(B,)çš„bool tensor
        
        Returns:
            åŒ…å«æ‰€æœ‰æ¨¡æ€å¯¹æŒ‡æ ‡çš„å­—å…¸ï¼Œé”®æ ¼å¼ä¸ºï¼š
            - {modality1}_{modality2}_recall_at_k
            - {modality1}_{modality2}_mrr
            - {modality1}_{modality2}_median_rank
            - {modality1}_{modality2}_positive_similarity
            - {modality1}_{modality2}_negative_similarity
            - {modality1}_{modality2}_similarity_gap
        """
        metrics = {}
        
        # è·å–æ‰€æœ‰æ¨¡æ€å¯¹
        modalities = list(features.keys())
        
        for i, mod1 in enumerate(modalities):
            for mod2 in modalities[i+1:]:
                if mod1 not in features or mod2 not in features:
                    continue
                
                feat1 = features[mod1]
                feat2 = features[mod2]
                
                # è·å–maskï¼ˆå¦‚æœæä¾›ï¼‰
                mask1 = modality_masks.get(mod1) if modality_masks else None
                mask2 = modality_masks.get(mod2) if modality_masks else None
                
                # åˆå¹¶maskï¼ˆä¸¤ä¸ªæ¨¡æ€éƒ½æœ‰æ•ˆæ‰è®¡ç®—ï¼‰
                if mask1 is not None and mask2 is not None:
                    mask = mask1 & mask2
                elif mask1 is not None:
                    mask = mask1
                elif mask2 is not None:
                    mask = mask2
                else:
                    mask = None
                
                # è®¡ç®—æ£€ç´¢æŒ‡æ ‡
                retrieval_metrics = self.compute_retrieval_metrics(feat1, feat2, mask)
                for key, value in retrieval_metrics.items():
                    metrics[f"{mod1}_{mod2}_{key}"] = value
                
                # è®¡ç®—ç›¸ä¼¼åº¦æŒ‡æ ‡
                similarity_metrics = self.compute_similarity_metrics(feat1, feat2, mask)
                for key, value in similarity_metrics.items():
                    metrics[f"{mod1}_{mod2}_{key}"] = value
        
        return metrics
    
    def compute_batch_metrics(
        self,
        features: Dict[str, torch.Tensor],
        modality_masks: Optional[Dict[str, torch.Tensor]] = None,
    ) -> Dict[str, float]:
        """
        è®¡ç®—batchçº§åˆ«çš„æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡
        
        è¿™æ˜¯ä¸»è¦çš„æ¥å£å‡½æ•°ï¼Œè¿”å›æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ã€‚
        
        Args:
            features: å¯¹é½åçš„ç‰¹å¾å­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸º(B, D)çš„tensor
            modality_masks: æ¨¡æ€maskå­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸º(B,)çš„bool tensor
        
        Returns:
            åŒ…å«æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸
        """
        return self.compute_alignment_score(features, modality_masks)
