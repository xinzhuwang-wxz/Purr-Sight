"""
ç¦»çº¿é¢„å¤„ç†è„šæœ¬ï¼šä¸€æ¬¡æ€§é¢„å¤„ç†æ‰€æœ‰æ•°æ®ï¼Œè®­ç»ƒæ—¶åªload tensor

åŠŸèƒ½ï¼š
1. è¯»å–åŸå§‹æ•°æ®ï¼ˆvideo/image/audio/textï¼‰
2. æ‰§è¡Œå®Œæ•´é¢„å¤„ç†ï¼š
   - video â†’ 16å¸§tensor (16, 3, 224, 224) + audio tensor (64, 256)
   - image â†’ tensor (3, 224, 224)
   - audio â†’ tensor (64, 256)
   - text â†’ token ids (seq_len,)
3. ä¿å­˜ä¸º.ptæ–‡ä»¶
4. ç”Ÿæˆç´¢å¼•æ–‡ä»¶ï¼ˆJSONLï¼‰ï¼ŒæŒ‡å‘é¢„å¤„ç†åçš„æ–‡ä»¶

åŒ…å«ï¼š
- compute_file_hash: è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œå€¼
- preprocess_sample: é¢„å¤„ç†å•ä¸ªæ ·æœ¬å¹¶ä¿å­˜
- load_data_from_jsonl: ä»JSONLæ–‡ä»¶åŠ è½½æ•°æ®
- main: ä¸»å‡½æ•°

ä½¿ç”¨æ–¹æ³•ï¼š
    python -m purrsight.preprocess.prepre --input_file data/train.jsonl --output_dir data/preprocessed
"""

import argparse
import json
import hashlib
from pathlib import Path
from typing import Dict, Any, List, Optional
import torch
import numpy as np
from tqdm import tqdm

from purrsight.preprocess import Preprocessor
from purrsight.config import FeatureKey, Modality, ROOT_DIR


def compute_file_hash(file_path: Path) -> str:
    """
    è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œå€¼
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
    
    Returns:
        MD5å“ˆå¸Œå€¼çš„åå…­è¿›åˆ¶å­—ç¬¦ä¸²
    """
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()


def _save_tensor(tensor_or_dict, file_path: Path) -> None:
    """
    ä¿å­˜tensor
    
    Args:
        tensor_or_dict: è¦ä¿å­˜çš„tensoræˆ–å­—å…¸
        file_path: ä¿å­˜è·¯å¾„
        
    Raises:
        Exception: å½“ä¿å­˜å¤±è´¥æ—¶
    """
    torch.save(tensor_or_dict, file_path)
    
    # åŸºæœ¬éªŒè¯ï¼šæ–‡ä»¶å­˜åœ¨ä¸”å¤§å°>0
    if not file_path.exists() or file_path.stat().st_size == 0:
        if file_path.exists():
            file_path.unlink()
        raise ValueError(f"ä¿å­˜çš„æ–‡ä»¶ä¸ºç©º: {file_path}")


def _check_file_exists(file_path: Path) -> bool:
    """
    æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¤§å°>0
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        
    Returns:
        æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¤§å°>0
    """
    return file_path.exists() and file_path.stat().st_size > 0


def preprocess_sample(
    sample: Dict[str, Any],
    preprocessor: Preprocessor,
    output_dir: Path,
    sample_idx: int,
    skip_existing: bool = True
) -> Optional[Dict[str, Any]]:
    """
    é¢„å¤„ç†å•ä¸ªæ ·æœ¬å¹¶ä¿å­˜
    
    Args:
        sample: åŸå§‹æ ·æœ¬å­—å…¸
        preprocessor: é¢„å¤„ç†å™¨å®ä¾‹
        output_dir: è¾“å‡ºç›®å½•
        sample_idx: æ ·æœ¬ç´¢å¼•
        skip_existing: å¦‚æœä¸ºTrueï¼Œè·³è¿‡å·²å­˜åœ¨çš„é¢„å¤„ç†æ–‡ä»¶ï¼ˆé»˜è®¤ï¼šTrueï¼‰
        
    Returns:
        é¢„å¤„ç†åçš„ç´¢å¼•æ¡ç›®ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        # æ„å»ºè¾“å‡ºæ–‡ä»¶åï¼ˆä½¿ç”¨ç´¢å¼•å’Œå“ˆå¸Œï¼‰
        sample_hash = hashlib.md5(str(sample).encode()).hexdigest()[:8]
        base_name = f"sample_{sample_idx:06d}_{sample_hash}"
        
        # ğŸ”§ æ”¹è¿›ï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        text_file = output_dir / f"{base_name}_text.pt"
        image_file = output_dir / f"{base_name}_image.pt"
        audio_file = output_dir / f"{base_name}_audio.pt"
        metadata_file = output_dir / f"{base_name}_metadata.pt"
        
        # å¦‚æœskip_existing=Trueï¼Œæ£€æŸ¥å·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œå¦‚æœæ‰€æœ‰åº”è¯¥å­˜åœ¨çš„æ–‡ä»¶éƒ½å­˜åœ¨ï¼Œåˆ™è·³è¿‡é¢„å¤„ç†
        if skip_existing:
            saved_files = {}
            expected_files = set()
            
            # æ£€æŸ¥æ–‡æœ¬
            if "text" in sample and sample.get("text"):
                expected_files.add("text")
                if _check_file_exists(text_file):
                    saved_files["text"] = str(text_file.relative_to(output_dir))
            
            # æ£€æŸ¥å›¾åƒï¼ˆå¦‚æœåŸå§‹æ ·æœ¬æœ‰imageï¼Œä¸”æ²¡æœ‰videoï¼‰
            if "image" in sample and sample.get("image") and "video" not in sample:
                expected_files.add("image")
                if _check_file_exists(image_file):
                    saved_files["image"] = str(image_file.relative_to(output_dir))
            
            # æ£€æŸ¥è§†é¢‘ï¼ˆå¦‚æœåŸå§‹æ ·æœ¬æœ‰videoï¼Œä¼šç”Ÿæˆimageå’Œmetadataï¼‰
            if "video" in sample and sample.get("video"):
                expected_files.add("image")
                expected_files.add("video_metadata")
                if _check_file_exists(image_file):
                    saved_files["image"] = str(image_file.relative_to(output_dir))
                if _check_file_exists(metadata_file):
                    saved_files["video_metadata"] = str(metadata_file.relative_to(output_dir))
            
            # æ£€æŸ¥éŸ³é¢‘
            if "audio" in sample and sample.get("audio"):
                expected_files.add("audio")
                if _check_file_exists(audio_file):
                    saved_files["audio"] = str(audio_file.relative_to(output_dir))
            
            # å¦‚æœæ‰€æœ‰æœŸæœ›çš„æ–‡ä»¶éƒ½å­˜åœ¨ï¼Œè·³è¿‡é¢„å¤„ç†
            if expected_files and len(saved_files) == len(expected_files):
                return {
                    "sample_idx": sample_idx,
                    "original_sample": sample,
                    "preprocessed_files": saved_files
                }
        
        # é¢„å¤„ç†æ ·æœ¬ï¼ˆå¤±è´¥ä¼šæŠ›å¼‚å¸¸ï¼‰
        features = preprocessor.process(sample)
        
        # ä¿å­˜å„ä¸ªæ¨¡æ€çš„ç‰¹å¾
        saved_files = {}
        
        # ä¿å­˜æ–‡æœ¬ç‰¹å¾
        if FeatureKey.TEXT in features:
            _save_tensor({
                "input_ids": torch.from_numpy(features[FeatureKey.TEXT]),
                "attention_mask": torch.from_numpy(features[FeatureKey.TEXT_ATTENTION_MASK])
            }, text_file)
            saved_files["text"] = str(text_file.relative_to(output_dir))
        
        # ä¿å­˜å›¾åƒç‰¹å¾
        if FeatureKey.IMAGE in features:
            image_tensor = torch.from_numpy(features[FeatureKey.IMAGE])
            _save_tensor(image_tensor, image_file)
            saved_files["image"] = str(image_file.relative_to(output_dir))
            
            # è®°å½•å›¾åƒå½¢çŠ¶ä¿¡æ¯
            if image_tensor.dim() == 3:
                saved_files["image_shape"] = list(image_tensor.shape)
        
        # ä¿å­˜éŸ³é¢‘ç‰¹å¾
        if FeatureKey.AUDIO in features:
            audio_tensor = torch.from_numpy(features[FeatureKey.AUDIO])
            _save_tensor(audio_tensor, audio_file)
            saved_files["audio"] = str(audio_file.relative_to(output_dir))
        
        # ä¿å­˜è§†é¢‘å…ƒæ•°æ®
        if "_video_metadata" in features:
            _save_tensor(features["_video_metadata"], metadata_file)
            saved_files["video_metadata"] = str(metadata_file.relative_to(output_dir))
        
        # æ„å»ºç´¢å¼•æ¡ç›®
        index_entry = {
            "sample_idx": sample_idx,
            "original_sample": sample,  # ä¿ç•™åŸå§‹æ ·æœ¬ä¿¡æ¯
            "preprocessed_files": saved_files
        }
        
        return index_entry
        
    except Exception as e:
        print(f"é¢„å¤„ç†æ ·æœ¬ {sample_idx} å¤±è´¥: {e}")
        return None


def load_data_from_jsonl(file_path: Path) -> List[Dict[str, Any]]:
    """
    ä»JSONLæ–‡ä»¶åŠ è½½æ•°æ®
    
    Args:
        file_path: JSONLæ–‡ä»¶è·¯å¾„
    
    Returns:
        æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªæ ·æœ¬å­—å…¸
    """
    data_list = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                data_list.append(json.loads(line))
    return data_list


def main():
    """
    ä¸»å‡½æ•°ï¼šç¦»çº¿é¢„å¤„ç†æ•°æ®
    
    ä»JSONLæ–‡ä»¶è¯»å–åŸå§‹æ•°æ®ï¼Œé¢„å¤„ç†åä¿å­˜ä¸º.ptæ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆç´¢å¼•æ–‡ä»¶ã€‚
    """
    parser = argparse.ArgumentParser(description="ç¦»çº¿é¢„å¤„ç†æ•°æ®")
    parser.add_argument(
        "--input_file",
        type=str,
        required=True,
        help="è¾“å…¥JSONLæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="data/preprocessed",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šdata/preprocessedï¼‰"
    )
    parser.add_argument(
        "--index_file",
        type=str,
        default=None,
        help="ç´¢å¼•æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šoutput_dir/index.jsonlï¼‰"
    )
    parser.add_argument(
        "--num_workers",
        type=int,
        default=1,
        help="å¹¶è¡Œå¤„ç†workeræ•°ï¼ˆé»˜è®¤ï¼š1ï¼Œå•è¿›ç¨‹ï¼‰"
    )
    parser.add_argument(
        "--force_reprocess",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°é¢„å¤„ç†æ‰€æœ‰æ ·æœ¬ï¼ˆå³ä½¿æ–‡ä»¶å·²å­˜åœ¨ï¼‰"
    )
    parser.add_argument(
        "--cleanup_corrupted",
        action="store_true",
        help="æ¸…ç†æŸåçš„æ–‡ä»¶å¹¶é‡æ–°é¢„å¤„ç†"
    )
    
    args = parser.parse_args()
    
    # è§£æè·¯å¾„
    input_file = Path(args.input_file)
    if not input_file.exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
    
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    index_file = Path(args.index_file) if args.index_file else output_dir / "index.jsonl"
    
    # åŠ è½½æ•°æ®
    print(f"åŠ è½½æ•°æ®ä»: {input_file}")
    data_list = load_data_from_jsonl(input_file)
    print(f"å…± {len(data_list)} ä¸ªæ ·æœ¬")
    
    # åˆå§‹åŒ–é¢„å¤„ç†å™¨
    preprocessor = Preprocessor()
    
    # é¢„å¤„ç†æ‰€æœ‰æ ·æœ¬
    print(f"å¼€å§‹é¢„å¤„ç†ï¼Œè¾“å‡ºç›®å½•: {output_dir}")
    index_entries = []
    
    # ğŸ”§ æ”¹è¿›ï¼šæ·»åŠ è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶çš„é€‰é¡¹ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
    skip_existing = not args.force_reprocess  # å¦‚æœforce_reprocess=Trueï¼Œåˆ™skip_existing=False
    skipped_count = 0
    reprocessed_count = 0
    
    # ğŸ”§ ä¿®å¤ï¼šå¦‚æœcleanup_corrupted=Trueï¼Œå…ˆæ‰«æå¹¶åˆ é™¤æŸåçš„æ–‡ä»¶
    if args.cleanup_corrupted:
        print("æ¸…ç†æŸåçš„æ–‡ä»¶...")
        corrupted_count = 0
        for pt_file in output_dir.glob("*.pt"):
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å‡½æ•°å
            if not _check_file_exists(pt_file):
                corrupted_count += 1
                pt_file.unlink(missing_ok=True)
        print(f"  å‘ç°å¹¶åˆ é™¤ {corrupted_count} ä¸ªæŸåçš„æ–‡ä»¶")
    
    # ğŸ”§ æ”¹è¿›ï¼šå¹¶è¡Œå¤„ç†
    if args.num_workers > 1:
        print(f"ä½¿ç”¨ {args.num_workers} ä¸ªworkerå¹¶è¡Œå¤„ç†...")
        from concurrent.futures import ProcessPoolExecutor, as_completed
        
        with ProcessPoolExecutor(max_workers=args.num_workers) as executor:
            futures = []
            for idx, sample in enumerate(data_list):
                futures.append(executor.submit(preprocess_sample, sample, preprocessor, output_dir, idx, skip_existing))
            
            for future in tqdm(as_completed(futures), total=len(futures), desc="é¢„å¤„ç†ä¸­ (å¹¶è¡Œ)"):
                try:
                    index_entry = future.result()
                    if index_entry:
                        index_entries.append(index_entry)
                except Exception as e:
                    print(f"Worker exception: {e}")
    else:
        for idx, sample in enumerate(tqdm(data_list, desc="é¢„å¤„ç†ä¸­")):
            index_entry = preprocess_sample(sample, preprocessor, output_dir, idx, skip_existing=skip_existing)
            if index_entry:
                index_entries.append(index_entry)
    
    # ä¿å­˜ç´¢å¼•æ–‡ä»¶
    print(f"ä¿å­˜ç´¢å¼•æ–‡ä»¶: {index_file}")
    with open(index_file, 'w', encoding='utf-8') as f:
        for entry in index_entries:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')
    
    print(f"\né¢„å¤„ç†å®Œæˆï¼")
    print(f"  - æˆåŠŸå¤„ç†: {len(index_entries)}/{len(data_list)} ä¸ªæ ·æœ¬")
    if skip_existing:
        print(f"  - è·³è¿‡å·²å­˜åœ¨çš„æœ‰æ•ˆæ–‡ä»¶")
    if args.force_reprocess:
        print(f"  - å¼ºåˆ¶é‡æ–°é¢„å¤„ç†æ¨¡å¼ï¼ˆæ‰€æœ‰æ–‡ä»¶å·²é‡æ–°ç”Ÿæˆï¼‰")
    if args.cleanup_corrupted:
        print(f"  - å·²æ¸…ç†æŸåçš„æ–‡ä»¶")
    print(f"  - è¾“å‡ºç›®å½•: {output_dir}")
    print(f"  - ç´¢å¼•æ–‡ä»¶: {index_file}")


if __name__ == "__main__":
    main()
