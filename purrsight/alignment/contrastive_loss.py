"""
å¯¹æ¯”æŸå¤±æ¨¡å—ï¼šInfoNCEæŸå¤±å®ç°

å‚è€ƒImageBindè®¾è®¡ï¼Œä½¿ç”¨InfoNCEæŸå¤±è¿›è¡Œè·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ ã€‚
æ”¯æŒå¯¹ç§°æŸå¤±å’Œæ¨¡æ€ç¼ºå¤±çš„æƒ…å†µã€‚

åŒ…å«ï¼š
- infonce_loss: InfoNCEæŸå¤±å‡½æ•°
- ContrastiveLoss: å¯¹æ¯”æŸå¤±ç±»

å‚è€ƒä»“åº“ï¼š
- openai/CLIP (OpenCLIP)
"""

import torch
import torch.nn.functional as F
from typing import Dict, Optional, Tuple


def infonce_loss(
    query_features: torch.Tensor,
    key_features: torch.Tensor,
    temperature: Optional[float] = None,
    logit_scale: Optional[torch.Tensor] = None,
    mask: Optional[torch.Tensor] = None,
) -> torch.Tensor:
    """
    InfoNCEæŸå¤±å‡½æ•°
    
    è®¡ç®—queryå’Œkeyä¹‹é—´çš„å¯¹æ¯”æŸå¤±ã€‚å‡è®¾æ‰¹æ¬¡ä¸­ç¬¬iä¸ªqueryå’Œç¬¬iä¸ªkeyæ˜¯æ­£æ ·æœ¬å¯¹ï¼Œ
    å…¶ä»–ç»„åˆæ˜¯è´Ÿæ ·æœ¬å¯¹ã€‚
    
    InfoNCEæ˜¯å¯¹æ•´ä¸ªbatchè®¡ç®—çš„ï¼Œä¼šè®¡ç®—æ‰€æœ‰æ ·æœ¬ä¹‹é—´çš„ç›¸ä¼¼åº¦çŸ©é˜µ(B, B)ï¼š
    - å¯¹è§’çº¿å…ƒç´ (i, i)æ˜¯æ­£æ ·æœ¬å¯¹ï¼ˆåŒä¸€ä¸ªæ ·æœ¬çš„ä¸åŒæ¨¡æ€ï¼‰
    - éå¯¹è§’çº¿å…ƒç´ (i, j)æ˜¯è´Ÿæ ·æœ¬å¯¹ï¼ˆä¸åŒæ ·æœ¬çš„æ¨¡æ€ï¼‰
    
    å…¬å¼ï¼ˆqueryâ†’keyæ–¹å‘ï¼‰ï¼š
    L_q2k = (1/B) * Î£_i [-log(exp(sim(q_i, k_i) * Ï„) / Î£_j exp(sim(q_i, k_j) * Ï„))]
    
    å…¶ä¸­ï¼š
    - q_i: ç¬¬iä¸ªqueryç‰¹å¾
    - k_i: ç¬¬iä¸ªkeyç‰¹å¾ï¼ˆæ­£æ ·æœ¬ï¼‰
    - k_j: ç¬¬jä¸ªkeyç‰¹å¾ï¼ˆåŒ…æ‹¬æ­£æ ·æœ¬j=iå’Œè´Ÿæ ·æœ¬jâ‰ iï¼‰
    - Ï„: æ¸©åº¦å‚æ•° = exp(logit_scale)
    - sim(Â·,Â·): ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆç‰¹å¾å·²å½’ä¸€åŒ–ï¼Œç‚¹ç§¯=ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
    - Î£_j: åŒ…å«æ‰€æœ‰æ ·æœ¬ï¼ˆæ­£æ ·æœ¬ + è´Ÿæ ·æœ¬ï¼‰ï¼Œä¸åªæ˜¯è´Ÿæ ·æœ¬
    
    å¯¹ç§°æŸå¤±ï¼š
    L = (L_q2k + L_k2q) / 2.0
    
    æ³¨æ„ï¼š
    - æ¸©åº¦ç¼©æ”¾ä½¿ç”¨ä¹˜æ³•ï¼š`similarity * logit_scale`ï¼Œå…¶ä¸­ `logit_scale = exp(logit_scale_param)`
    - ç­‰ä»·äºé™¤æ³•å½¢å¼ï¼š`similarity / temperature`ï¼Œå…¶ä¸­ `temperature = 1 / exp(logit_scale_param)`
    
    Args:
        query_features: Queryç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(B, D)ï¼Œå·²å½’ä¸€åŒ–ï¼Œdtype=float32
            ç¼ºå¤±çš„æ¨¡æ€ç”¨é›¶å‘é‡å¡«å……ï¼ˆpadding 0ï¼‰
        key_features: Keyç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(B, D)ï¼Œå·²å½’ä¸€åŒ–ï¼Œdtype=float32
            ç¼ºå¤±çš„æ¨¡æ€ç”¨é›¶å‘é‡å¡«å……ï¼ˆpadding 0ï¼‰
        temperature: æ¸©åº¦å‚æ•°ï¼Œå¦‚æœæä¾›ï¼Œä¼šè¦†ç›–logit_scale
        logit_scale: å¯å­¦ä¹ çš„logit scaleï¼ˆexp(logit_scale)ä½œä¸ºæ¸©åº¦ï¼‰ï¼Œ
            å¦‚æœæä¾›ï¼Œä¼šè¦†ç›–temperature
        mask: Sample-level maskï¼Œå½¢çŠ¶ä¸º(B,)ï¼Œdtype=boolï¼ŒTrueè¡¨ç¤ºæœ‰æ•ˆæ ·æœ¬
            å¦‚æœæä¾›ï¼Œåªè®¡ç®—æœ‰æ•ˆæ ·æœ¬çš„æŸå¤±ï¼ˆä½†æ•´ä¸ªbatchä»å‚ä¸ç›¸ä¼¼åº¦è®¡ç®—ï¼‰
    
    Returns:
        InfoNCEæŸå¤±å€¼ï¼Œæ ‡é‡å¼ é‡ï¼Œdtype=float32
    """
    B = query_features.shape[0]
    device = query_features.device
    
    # éªŒè¯è¾“å…¥å½¢çŠ¶
    if query_features.shape != key_features.shape:
        raise ValueError(
            f"Queryå’ŒKeyç‰¹å¾å½¢çŠ¶ä¸åŒ¹é…ï¼š"
            f"query {query_features.shape} vs key {key_features.shape}"
        )
    
    # ğŸ”§ ä¼˜åŒ–ï¼šæ£€æŸ¥æ˜¯å¦æœ‰NaNæˆ–Infï¼ˆé›¶å‘é‡ç»è¿‡å½’ä¸€åŒ–ååº”è¯¥ä¿æŒä¸ºé›¶å‘é‡ï¼Œä¸åº”è¯¥æœ‰NaNï¼‰
    valid_mask = ~torch.isnan(query_features.sum(dim=1)) & ~torch.isnan(key_features.sum(dim=1))
    valid_mask = valid_mask & ~torch.isinf(query_features.sum(dim=1)) & ~torch.isinf(key_features.sum(dim=1))
    
    # ğŸ”§ ä¼˜åŒ–ï¼šå¦‚æœæä¾›äº†maskï¼Œä¸valid_maskåˆå¹¶ï¼ˆmask=Falseçš„æ ·æœ¬åº”è¯¥è¢«å®Œå…¨æ’é™¤ï¼‰
    if mask is not None:
        if mask.shape[0] != B:
            raise ValueError(f"Maskå½¢çŠ¶ä¸åŒ¹é…ï¼šmask {mask.shape} vs batch size {B}")
        # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šæ£€æŸ¥maskè®¾å¤‡ï¼Œé¿å…é‡å¤ä¼ è¾“
        if mask.device != device:
            mask = mask.to(device)
        # mask=Falseçš„æ ·æœ¬åº”è¯¥è¢«å®Œå…¨æ’é™¤ï¼ˆä¸å‚ä¸ç›¸ä¼¼åº¦è®¡ç®—ï¼‰
        valid_mask = valid_mask & mask
    
    # æ£€æŸ¥æœ‰æ•ˆæ ·æœ¬æ•°é‡
    valid_count = valid_mask.sum().item()
    if valid_count == 0:
        # æ²¡æœ‰æœ‰æ•ˆæ ·æœ¬ï¼Œè¿”å›0æŸå¤±ï¼ˆéœ€è¦æ¢¯åº¦ä¿¡æ¯ï¼‰
        from purrsight.utils.logging import logger
        logger.debug(f"æ‰€æœ‰æ ·æœ¬è¢«maskï¼Œè·³è¿‡{query_features.shape[0]}ä¸ªæ ·æœ¬çš„InfoNCEæŸå¤±è®¡ç®—")
        return torch.tensor(0.0, device=device, dtype=torch.float32, requires_grad=True)
    
    if valid_count < 2:
        # InfoNCEéœ€è¦è‡³å°‘2ä¸ªæœ‰æ•ˆæ ·æœ¬æ‰èƒ½è®¡ç®—ï¼ˆéœ€è¦æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬ï¼‰
        from purrsight.utils.logging import logger
        logger.debug(f"æœ‰æ•ˆæ ·æœ¬æ•°ä¸è¶³ï¼ˆ{valid_count} < 2ï¼‰ï¼Œè·³è¿‡InfoNCEæŸå¤±è®¡ç®—")
        return torch.tensor(0.0, device=device, dtype=torch.float32, requires_grad=True)
    
    # ğŸ”§ ä¼˜åŒ–ï¼šè®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ (B, B)
    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨æ•´ä¸ªbatchè®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µï¼ŒåŒ…æ‹¬é›¶å‘é‡æ ·æœ¬
    # é›¶å‘é‡ä¸å…¶ä»–å‘é‡çš„ç›¸ä¼¼åº¦æ˜¯0ï¼Œè¿™æ˜¯åˆç†çš„
    # ä½†ç”±äºvalid_maskä¼šè¿‡æ»¤ï¼Œé›¶å‘é‡æ ·æœ¬ä¸ä¼šå‚ä¸æŸå¤±è®¡ç®—
    # ç”±äºç‰¹å¾å·²å½’ä¸€åŒ–ï¼Œç‚¹ç§¯ = ä½™å¼¦ç›¸ä¼¼åº¦
    logits = query_features @ key_features.T
    
    # ğŸ”§ CRITICAL FIX: Mask invalid keys (columns) to avoid gradient dilution
    # Invalid keys (zero vectors) produce dot product 0, so exp(0)=1 in Softmax denominator.
    # This dilutes the gradient for valid positive pairs.
    # We must mask them to -inf so exp(-inf)=0.
    if valid_mask is not None:
        # valid_mask shape: (B,)
        # Mask columns where key is invalid
        logits[:, ~valid_mask] = -1e9
    
    # åº”ç”¨æ¸©åº¦ç¼©æ”¾
    if logit_scale is not None:
        # ä½¿ç”¨å¯å­¦ä¹ çš„logit scale
        logits = logits * logit_scale
    elif temperature is not None:
        # ä½¿ç”¨å›ºå®šçš„æ¸©åº¦å‚æ•°
        logits = logits / temperature
    
    # æ ‡ç­¾ï¼šå¯¹è§’çº¿æ˜¯æ­£æ ·æœ¬å¯¹
    # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿labelsæ˜¯longç±»å‹ï¼ˆcross_entropyéœ€è¦ï¼‰
    labels = torch.arange(B, device=device, dtype=torch.long)
    
    # å¦‚æœåªæœ‰éƒ¨åˆ†æ ·æœ¬æœ‰æ•ˆï¼Œåªè®¡ç®—æœ‰æ•ˆæ ·æœ¬çš„æŸå¤±
    if valid_count < B:
        # åªä½¿ç”¨æœ‰æ•ˆæ ·æœ¬è®¡ç®—æŸå¤±
        valid_logits = logits[valid_mask]  # (valid_count, B)
        valid_labels = labels[valid_mask]  # (valid_count,)
        
        # è®¡ç®—loss_q2kï¼šquery->keyæ–¹å‘
        # valid_logitsçš„å½¢çŠ¶æ˜¯(valid_count, B)ï¼Œvalid_labelsçš„å½¢çŠ¶æ˜¯(valid_count,)
        loss_q2k = F.cross_entropy(valid_logits, valid_labels)
        
        # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šcross_entropyé€šå¸¸è¿”å›float32ï¼Œdtypeæ£€æŸ¥ç§»åˆ°æœ€ç»ˆlossç»Ÿä¸€å¤„ç†
        
        # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šè®¡ç®—loss_k2qï¼škey->queryæ–¹å‘ï¼Œä½¿ç”¨ç›´æ¥ç´¢å¼•é¿å…è½¬ç½®
        # logits[i, j] è¡¨ç¤º query_i å’Œ key_j çš„ç›¸ä¼¼åº¦
        # å¯¹äº key->query æ–¹å‘ï¼Œæˆ‘ä»¬éœ€è¦ logits[j, i]ï¼ˆè½¬ç½®ï¼‰
        # ä½†æˆ‘ä»¬å¯ä»¥ç›´æ¥ç´¢å¼•æœ‰æ•ˆæ ·æœ¬ï¼Œé¿å…åˆ›å»ºè½¬ç½®è§†å›¾
        valid_indices = valid_mask.nonzero(as_tuple=True)[0]  # (valid_count,)
        # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šç›´æ¥æå–æœ‰æ•ˆæ ·æœ¬çš„å­çŸ©é˜µï¼Œé¿å…è½¬ç½®æ“ä½œ
        # logits[valid_indices][:, valid_indices] ç­‰ä»·äº logits.T[valid_indices][:, valid_indices]
        # ä½†æ›´é«˜æ•ˆï¼Œå› ä¸ºé¿å…äº†è½¬ç½®æ“ä½œ
        valid_logits_k2q = logits[valid_indices][:, valid_indices]  # (valid_count, valid_count)
        transposed_labels = torch.arange(valid_count, device=device, dtype=torch.long)  # (valid_count,)
        
        loss_k2q = F.cross_entropy(valid_logits_k2q, transposed_labels)
        
        # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šcross_entropyé€šå¸¸è¿”å›float32ï¼Œåªåœ¨å¿…è¦æ—¶æ£€æŸ¥
        # å¦‚æœcross_entropyè¿”å›éfloat32ï¼Œä¼šåœ¨training_stepä¸­ç»Ÿä¸€å¤„ç†
    else:
        # æ‰€æœ‰æ ·æœ¬éƒ½æœ‰æ•ˆï¼Œè®¡ç®—å¯¹ç§°æŸå¤±
        # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿labelsæ˜¯longç±»å‹ï¼ˆcross_entropyéœ€è¦ï¼‰
        if labels.dtype != torch.long:
            labels = labels.long()
        
        loss_q2k = F.cross_entropy(logits, labels)
        # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨torch.transposeè€Œä¸æ˜¯.Tï¼Œæ›´æ˜ç¡®ä¸”å¯èƒ½æ›´é«˜æ•ˆ
        loss_k2q = F.cross_entropy(torch.transpose(logits, 0, 1), labels)
        
        # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šcross_entropyé€šå¸¸è¿”å›float32ï¼Œåªåœ¨å¿…è¦æ—¶æ£€æŸ¥
        # å¦‚æœcross_entropyè¿”å›éfloat32ï¼Œä¼šåœ¨training_stepä¸­ç»Ÿä¸€å¤„ç†
    
    # å¹³å‡æŸå¤±
    loss = (loss_q2k + loss_k2q) / 2.0
    
    # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šcross_entropyé€šå¸¸è¿”å›float32ï¼Œè¿™é‡Œåªåšæœ€ç»ˆæ£€æŸ¥
    # å¦‚æœcross_entropyè¿”å›éfloat32ï¼Œä¼šåœ¨training_stepä¸­ç»Ÿä¸€å¤„ç†
    # è¿™é‡Œä¿ç•™æ£€æŸ¥ä»¥ç¡®ä¿å…¼å®¹æ€§ï¼Œä½†cross_entropyåº”è¯¥æ€»æ˜¯è¿”å›float32
    
    return loss


class ContrastiveLoss:
    """
    å¤šæ¨¡æ€å¯¹æ¯”æŸå¤±è®¡ç®—å™¨
    
    æ”¯æŒå¤šæ¨¡æ€ä¹‹é—´çš„å¯¹æ¯”å­¦ä¹ ï¼Œè‡ªåŠ¨å¤„ç†æ¨¡æ€ç¼ºå¤±çš„æƒ…å†µã€‚
    å‚è€ƒImageBindè®¾è®¡ï¼Œè®¡ç®—æ‰€æœ‰æ¨¡æ€å¯¹ä¹‹é—´çš„InfoNCEæŸå¤±ã€‚
    
    Attributes:
        use_temperature_scaling: æ˜¯å¦ä½¿ç”¨æ¸©åº¦ç¼©æ”¾
        default_temperature: é»˜è®¤æ¸©åº¦å‚æ•°
    """
    
    def __init__(
        self,
        use_temperature_scaling: bool = True,
        default_temperature: float = 0.07,
    ):
        """
        åˆå§‹åŒ–å¯¹æ¯”æŸå¤±è®¡ç®—å™¨
        
        Args:
            use_temperature_scaling: æ˜¯å¦ä½¿ç”¨æ¸©åº¦ç¼©æ”¾ï¼Œé»˜è®¤True
            default_temperature: é»˜è®¤æ¸©åº¦å‚æ•°ï¼ˆå½“ä¸ä½¿ç”¨æ¸©åº¦ç¼©æ”¾æ—¶ï¼‰ï¼Œé»˜è®¤0.07
        """
        self.use_temperature_scaling = use_temperature_scaling
        self.default_temperature = default_temperature
    
    def compute_loss(
        self,
        features: Dict[str, torch.Tensor],
        modality_presence: Optional[Dict[str, bool]] = None,
        logit_scales: Optional[Dict[str, torch.Tensor]] = None,
        modality_masks: Optional[Dict[str, torch.Tensor]] = None,
    ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        è®¡ç®—å¤šæ¨¡æ€å¯¹æ¯”æŸå¤±
        
        è®¡ç®—æ‰€æœ‰å­˜åœ¨çš„æ¨¡æ€å¯¹ä¹‹é—´çš„InfoNCEæŸå¤±ï¼Œå¹¶è¿”å›æ€»æŸå¤±å’Œå„é¡¹æŸå¤±ã€‚
        è§†é¢‘æ•°æ®å·²åˆ†è§£ä¸ºå›¾åƒå’ŒéŸ³é¢‘ï¼Œç›´æ¥å‚ä¸æ ‡å‡†æŸå¤±è®¡ç®—ã€‚
        
        Args:
            features: åå¤„ç†åçš„ç‰¹å¾å­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸ºç‰¹å¾å¼ é‡
                å½¢çŠ¶ä¸º(B, 512)ï¼Œå·²å½’ä¸€åŒ–ï¼Œdtype=float32ï¼ˆåŒ¹é…LLM embeddingç»´åº¦ï¼‰
            modality_presence: æ¨¡æ€å­˜åœ¨æ ‡è®°å­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸ºbool
                å¦‚æœä¸ºNoneï¼Œåˆ™æ ¹æ®featuresä¸­çš„é”®è‡ªåŠ¨æ¨æ–­
            logit_scales: logit scaleå­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸ºlogit scaleå¼ é‡
                å¦‚æœä¸ºNoneä¸”use_temperature_scaling=Trueï¼Œåˆ™ä½¿ç”¨default_temperature
            modality_masks: Sample-levelæ¨¡æ€maskå­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸ºå½¢çŠ¶ä¸º(B,)çš„bool tensor
                è¡¨ç¤ºbatchä¸­æ¯ä¸ªæ ·æœ¬çš„æ¨¡æ€æ˜¯å¦å­˜åœ¨ï¼Œç”¨äºç²¾ç¡®æ§åˆ¶æŸå¤±è®¡ç®—
        
        Returns:
            (total_loss, loss_dict)å…ƒç»„ï¼š
            - total_loss: æ€»æŸå¤±å€¼ï¼Œæ ‡é‡å¼ é‡
            - loss_dict: å„é¡¹æŸå¤±å­—å…¸ï¼Œé”®ä¸º"modality1_modality2"ï¼Œå€¼ä¸ºæŸå¤±å€¼
        """
        # ğŸ”§ ä¼˜åŒ–ï¼šä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„modality_presenceï¼Œé¿å…é‡å¤æ¨æ–­
        # å¦‚æœæ²¡æœ‰æä¾›modality_presenceï¼Œæ ¹æ®featureså’Œmodality_masksè‡ªåŠ¨æ¨æ–­
        if modality_presence is None:
            from purrsight.config import Modality
            modality_presence = {}
            for modality in [Modality.TEXT, Modality.IMAGE, Modality.AUDIO]:
                modality_key = modality.value
                # ä¼˜å…ˆä½¿ç”¨modality_masksåˆ¤æ–­ï¼ˆæ›´å‡†ç¡®ï¼‰
                if modality_masks is not None and modality_key in modality_masks:
                    mask = modality_masks[modality_key]
                    # å¦‚æœmaskä¸­è‡³å°‘æœ‰ä¸€ä¸ªTrueï¼Œè¯´æ˜batchä¸­è‡³å°‘æœ‰ä¸€ä¸ªæ ·æœ¬æœ‰è¯¥æ¨¡æ€
                    modality_presence[modality_key] = mask.any().item() if mask.numel() > 0 else False
                else:
                    # å›é€€åˆ°featuresåˆ¤æ–­
                    modality_presence[modality_key] = (
                        modality_key in features
                        and features[modality_key] is not None
                        and not torch.all(features[modality_key] == 0)  # æ’é™¤é›¶å‘é‡
                    )
        
        # è·å–å­˜åœ¨çš„æ¨¡æ€åˆ—è¡¨
        present_modalities = [
            modality
            for modality, present in modality_presence.items()
            if present
        ]
        
        if len(present_modalities) < 2:
            # è‡³å°‘éœ€è¦ä¸¤ä¸ªæ¨¡æ€æ‰èƒ½è®¡ç®—å¯¹æ¯”æŸå¤±
            device = next(iter(features.values())).device
            from purrsight.utils.logging import logger
            logger.debug(f"æ¨¡æ€æ•°é‡ä¸è¶³ï¼ˆ{len(present_modalities)} < 2ï¼‰ï¼Œè·³è¿‡å¯¹æ¯”æŸå¤±è®¡ç®—")
            return torch.tensor(0.0, device=device, dtype=torch.float32, requires_grad=True), {}
        
        losses = {}
        loss_pairs = []

        # è®¡ç®—æ‰€æœ‰æ¨¡æ€å¯¹ä¹‹é—´çš„æŸå¤±ï¼ˆè§†é¢‘æ ·æœ¬çš„imageå’Œaudioä¸ç‹¬ç«‹æ ·æœ¬ä¸€æ ·å‚ä¸è®¡ç®—ï¼‰
        for i, modality1 in enumerate(present_modalities):
            for modality2 in present_modalities[i + 1:]:
                feat1 = features[modality1]
                feat2 = features[modality2]
                
                # ç¡®å®šæ¸©åº¦å‚æ•°
                temperature = None
                logit_scale = None
                
                if self.use_temperature_scaling:
                    if logit_scales is not None:
                        # ä½¿ç”¨ä¸¤ä¸ªæ¨¡æ€çš„å¹³å‡logit scale
                        scale1 = logit_scales.get(modality1, None)
                        scale2 = logit_scales.get(modality2, None)
                        if scale1 is not None and scale2 is not None:
                            logit_scale = (scale1 + scale2) / 2.0
                        elif scale1 is not None:
                            logit_scale = scale1
                        elif scale2 is not None:
                            logit_scale = scale2
                        else:
                            temperature = self.default_temperature
                    else:
                        temperature = self.default_temperature
                else:
                    temperature = self.default_temperature
                
                # åˆ›å»ºsample-level maskï¼šä¸¤ä¸ªæ¨¡æ€éƒ½æœ‰æ•ˆçš„æ ·æœ¬
                mask = None
                if modality_masks is not None:
                    mask1 = modality_masks.get(modality1)
                    mask2 = modality_masks.get(modality2)
                    if mask1 is not None and mask2 is not None:
                        # ç¡®ä¿maskåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼ˆä¸ç‰¹å¾ç›¸åŒï¼‰
                        device = feat1.device
                        B = feat1.shape[0]
                        
                        # éªŒè¯å¹¶ä¿®æ­£mask1å½¢çŠ¶
                        if mask1.dim() != 1:
                            # å¦‚æœä¸æ˜¯1ç»´ï¼Œå°è¯•squeezeæˆ–reshape
                            if mask1.numel() == B:
                                mask1 = mask1.view(B)
                            else:
                                raise ValueError(
                                    f"modality mask {modality1} å½¢çŠ¶ä¸æ­£ç¡®: "
                                    f"shape={mask1.shape}, numel={mask1.numel()}, expected ({B},)"
                                )
                        elif mask1.shape[0] != B:
                            raise ValueError(
                                f"modality mask {modality1} batch sizeä¸åŒ¹é…: "
                                f"shape={mask1.shape}, expected ({B},)"
                            )
                        
                        # éªŒè¯å¹¶ä¿®æ­£mask2å½¢çŠ¶
                        if mask2.dim() != 1:
                            # å¦‚æœä¸æ˜¯1ç»´ï¼Œå°è¯•squeezeæˆ–reshape
                            if mask2.numel() == B:
                                mask2 = mask2.view(B)
                            else:
                                raise ValueError(
                                    f"modality mask {modality2} å½¢çŠ¶ä¸æ­£ç¡®: "
                                    f"shape={mask2.shape}, numel={mask2.numel()}, expected ({B},)"
                                )
                        elif mask2.shape[0] != B:
                            raise ValueError(
                                f"modality mask {modality2} batch sizeä¸åŒ¹é…: "
                                f"shape={mask2.shape}, expected ({B},)"
                            )
                        
                        # ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šæ£€æŸ¥è®¾å¤‡ï¼Œé¿å…é‡å¤ä¼ è¾“
                        if mask1.device != device:
                            mask1 = mask1.to(device)
                        if mask2.device != device:
                            mask2 = mask2.to(device)
                        mask = mask1 & mask2  # ä¸¤ä¸ªæ¨¡æ€éƒ½æœ‰æ•ˆçš„æ ·æœ¬

                # è®¡ç®—InfoNCEæŸå¤±
                pair_loss = infonce_loss(
                    feat1, feat2, temperature=temperature, logit_scale=logit_scale, mask=mask
                )
                
                pair_name = f"{modality1}_{modality2}"
                losses[pair_name] = pair_loss
                loss_pairs.append(pair_loss)

        # è®¡ç®—å¹³å‡æŸå¤±
        if len(loss_pairs) > 0:
            total_loss = sum(loss_pairs) / len(loss_pairs)
            # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿lossçš„dtypeæ˜¯float32ï¼ˆmixed precisionè®­ç»ƒéœ€è¦ï¼‰
            if total_loss.dtype != torch.float32:
                total_loss = total_loss.float()
        else:
            device = next(iter(features.values())).device
            total_loss = torch.tensor(0.0, device=device, dtype=torch.float32, requires_grad=True)
        
        return total_loss, losses


    def __call__(
        self,
        features: Dict[str, torch.Tensor],
        modality_presence: Optional[Dict[str, bool]] = None,
        logit_scales: Optional[Dict[str, torch.Tensor]] = None,
        modality_masks: Optional[Dict[str, torch.Tensor]] = None,
    ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        è°ƒç”¨compute_lossæ–¹æ³•
        
        Args:
            features: åå¤„ç†åçš„ç‰¹å¾å­—å…¸
            modality_presence: æ¨¡æ€å­˜åœ¨æ ‡è®°å­—å…¸
            logit_scales: logit scaleå­—å…¸
            modality_masks: Sample-levelæ¨¡æ€maskå­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸ºå½¢çŠ¶ä¸º(B,)çš„bool tensor
        
        Returns:
            (total_loss, loss_dict)å…ƒç»„
        """
        return self.compute_loss(features, modality_presence, logit_scales, modality_masks)

