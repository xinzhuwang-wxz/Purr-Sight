"""
åå¤„ç†å™¨æ¨¡å—ï¼šL2å½’ä¸€åŒ–å’Œæ¸©åº¦ç¼©æ”¾

å‚è€ƒImageBindè®¾è®¡ï¼Œæ‰€æœ‰æ¨¡æ€éƒ½ç»è¿‡L2å½’ä¸€åŒ–ï¼Œéƒ¨åˆ†æ¨¡æ€ä½¿ç”¨å¯å­¦ä¹ çš„æ¸©åº¦ç¼©æ”¾ã€‚

åŒ…å«ï¼š
- LearnableLogitScaling: å¯å­¦ä¹ çš„logitç¼©æ”¾ç±»
- Normalize: L2å½’ä¸€åŒ–å±‚ç±»
- Postprocessors: å¤šæ¨¡æ€åå¤„ç†å™¨é›†åˆç±»
- _get_device_from_features: è¾…åŠ©å‡½æ•°ï¼Œä»ç‰¹å¾å­—å…¸è·å–è®¾å¤‡

å‚è€ƒä»“åº“ï¼š
- openai/CLIP (OpenCLIP)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Optional
from purrsight.config import Modality


def _get_device_from_features(features: Dict[str, torch.Tensor]) -> torch.device:
    """
    ä»ç‰¹å¾å­—å…¸ä¸­è·å–è®¾å¤‡
    
    Args:
        features: ç‰¹å¾å­—å…¸
    
    Returns:
        ç‰¹å¾æ‰€åœ¨çš„è®¾å¤‡ï¼Œå¦‚æœå­—å…¸ä¸ºç©ºåˆ™è¿”å›CPUè®¾å¤‡
    """
    return next(iter(features.values())).device if features else torch.device("cpu")


class LearnableLogitScaling(nn.Module):
    """
    å¯å­¦ä¹ çš„logitç¼©æ”¾ï¼ˆæ¸©åº¦å‚æ•°ï¼‰
    
    å‚è€ƒImageBindè®¾è®¡ï¼Œä½¿ç”¨å¯å­¦ä¹ çš„logit scaleä½œä¸ºæ¸©åº¦å‚æ•°ã€‚
    åœ¨InfoNCEæŸå¤±ä¸­ï¼Œç›¸ä¼¼åº¦çŸ©é˜µä¼šä¹˜ä»¥exp(logit_scale)ã€‚
    
    Attributes:
        logit_scale: logit scaleå‚æ•°ï¼ˆParameteræˆ–Bufferï¼‰
        learnable: æ˜¯å¦å¯å­¦ä¹ 
    """
    
    def __init__(
        self,
        logit_scale_init: float = 1.0,
        learnable: bool = True,
    ):
        """
        åˆå§‹åŒ–å¯å­¦ä¹ çš„logitç¼©æ”¾
        
        Args:
            logit_scale_init: logit scaleçš„åˆå§‹å€¼ï¼Œé»˜è®¤1.0
                é€šå¸¸ä½¿ç”¨log(1/0.07) â‰ˆ 2.66ä½œä¸ºåˆå§‹å€¼ï¼ˆCLIPé£æ ¼ï¼‰
            learnable: æ˜¯å¦å¯å­¦ä¹ ï¼Œé»˜è®¤True
        """
        super().__init__()
        if learnable:
            # ä½¿ç”¨logç©ºé—´åˆå§‹åŒ–ï¼Œé¿å…æ•°å€¼ä¸ç¨³å®š
            self.logit_scale = nn.Parameter(torch.ones([]) * logit_scale_init)
        else:
            # å›ºå®šå€¼ï¼Œä¸å‚ä¸æ¢¯åº¦æ›´æ–°
            self.register_buffer("logit_scale", torch.tensor(logit_scale_init))
        self.learnable = learnable
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        åº”ç”¨logitç¼©æ”¾
        
        Args:
            x: è¾“å…¥ç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(B, D)ï¼Œdtype=float32
        
        Returns:
            ç¼©æ”¾åçš„ç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(B, D)ï¼Œdtype=float32
        """
        return x * self.logit_scale.exp()


class Normalize(nn.Module):
    """
    L2å½’ä¸€åŒ–å±‚
    
    å°†ç‰¹å¾å‘é‡å½’ä¸€åŒ–ä¸ºå•ä½å‘é‡ï¼Œä½¿å¾—ç‚¹ç§¯ç­‰äºä½™å¼¦ç›¸ä¼¼åº¦ã€‚
    å¯¹äºé›¶å‘é‡ï¼Œä¿æŒä¸ºé›¶å‘é‡ï¼ˆä¸å½’ä¸€åŒ–ï¼‰ã€‚
    
    Attributes:
        dim: å½’ä¸€åŒ–çš„ç»´åº¦
        eps: é˜²æ­¢é™¤é›¶çš„å°å€¼
    """
    
    def __init__(self, dim: int = -1, eps: float = 1e-8):
        """
        åˆå§‹åŒ–å½’ä¸€åŒ–å±‚
        
        Args:
            dim: å½’ä¸€åŒ–çš„ç»´åº¦ï¼Œé»˜è®¤-1ï¼ˆæœ€åä¸€ç»´ï¼‰
            eps: é˜²æ­¢é™¤é›¶çš„å°å€¼ï¼Œé»˜è®¤1e-8
        """
        super().__init__()
        self.dim = dim
        self.eps = eps
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        L2å½’ä¸€åŒ–
        
        Args:
            x: è¾“å…¥ç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(B, D)ï¼Œdtype=float32
        
        Returns:
            å½’ä¸€åŒ–åçš„ç‰¹å¾ï¼Œå½¢çŠ¶ä¸º(B, D)ï¼Œdtype=float32
        """
        # æ£€æŸ¥é›¶å‘é‡ï¼šå¦‚æœæŸä¸ªæ ·æœ¬çš„L2èŒƒæ•°æ¥è¿‘0ï¼Œå½’ä¸€åŒ–åå¯èƒ½äº§ç”ŸNaN
        # å¯¹äºé›¶å‘é‡ï¼Œç›´æ¥è¿”å›é›¶å‘é‡ï¼ˆä¸å½’ä¸€åŒ–ï¼‰
        norms = x.norm(p=2, dim=self.dim, keepdim=True)  # (B, 1)
        # å¦‚æœèŒƒæ•°å°äºepsï¼Œè¯´æ˜æ˜¯é›¶å‘é‡ï¼Œä¿æŒåŸæ ·
        x_normalized = F.normalize(x, p=2, dim=self.dim, eps=self.eps)
        # å¯¹äºé›¶å‘é‡ï¼Œå½’ä¸€åŒ–åå¯èƒ½äº§ç”ŸNaNï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        zero_mask = norms.squeeze(-1) < self.eps  # (B,)
        if zero_mask.any():
            # é›¶å‘é‡ä¿æŒä¸ºé›¶å‘é‡
            x_normalized[zero_mask] = x[zero_mask]
        return x_normalized


class Postprocessors(nn.Module):
    """
    å¤šæ¨¡æ€åå¤„ç†å™¨é›†åˆ
    
    ä¸ºæ¯ä¸ªæ¨¡æ€åˆ›å»ºåå¤„ç†å™¨ï¼ŒåŒ…å«L2å½’ä¸€åŒ–å’Œå¯é€‰çš„æ¸©åº¦ç¼©æ”¾ã€‚
    å‚è€ƒImageBindè®¾è®¡ï¼Œæ‰€æœ‰æ¨¡æ€éƒ½ç»è¿‡L2å½’ä¸€åŒ–ï¼Œéƒ¨åˆ†æ¨¡æ€ä½¿ç”¨æ¸©åº¦ç¼©æ”¾ã€‚
    """
    
    def __init__(
        self,
        use_temperature_scaling: bool = True,
        text_logit_scale_init: float = 2.66,  # log(1/0.07)
        text_learnable: bool = True,
        image_logit_scale_init: float = 1.0,
        image_learnable: bool = True,
        audio_logit_scale_init: float = 2.66,  # log(1/0.07)ï¼Œä¸textç›¸åŒ
        audio_learnable: bool = False,
    ):
        """
        åˆå§‹åŒ–å¤šæ¨¡æ€åå¤„ç†å™¨
        
        Args:
            use_temperature_scaling: æ˜¯å¦ä½¿ç”¨æ¸©åº¦ç¼©æ”¾ï¼Œé»˜è®¤True
            text_logit_scale_init: æ–‡æœ¬æ¨¡æ€çš„logit scaleåˆå§‹å€¼ï¼Œé»˜è®¤2.66
            text_learnable: æ–‡æœ¬æ¨¡æ€çš„logit scaleæ˜¯å¦å¯å­¦ä¹ ï¼Œé»˜è®¤True
            image_logit_scale_init: å›¾åƒæ¨¡æ€çš„logit scaleåˆå§‹å€¼ï¼Œé»˜è®¤1.0
            image_learnable: å›¾åƒæ¨¡æ€çš„logit scaleæ˜¯å¦å¯å­¦ä¹ ï¼Œé»˜è®¤False
            audio_logit_scale_init: éŸ³é¢‘æ¨¡æ€çš„logit scaleåˆå§‹å€¼ï¼Œé»˜è®¤2.66
            audio_learnable: éŸ³é¢‘æ¨¡æ€çš„logit scaleæ˜¯å¦å¯å­¦ä¹ ï¼Œé»˜è®¤False
        """
        super().__init__()
        self.use_temperature_scaling = use_temperature_scaling
        
        # æ‰€æœ‰æ¨¡æ€éƒ½ä½¿ç”¨L2å½’ä¸€åŒ–
        self.normalize = Normalize(dim=-1)
        
        # ä¸ºæ¯ä¸ªæ¨¡æ€åˆ›å»ºæ¸©åº¦ç¼©æ”¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if use_temperature_scaling:
            self.text_scaling = LearnableLogitScaling(
                logit_scale_init=text_logit_scale_init,
                learnable=text_learnable,
            )
            self.image_scaling = LearnableLogitScaling(
                logit_scale_init=image_logit_scale_init,
                learnable=image_learnable,
            )
            self.audio_scaling = LearnableLogitScaling(
                logit_scale_init=audio_logit_scale_init,
                learnable=audio_learnable,
            )
        else:
            # ä¸ä½¿ç”¨æ¸©åº¦ç¼©æ”¾æ—¶ï¼Œåˆ›å»ºIdentityå±‚
            self.text_scaling = nn.Identity()
            self.image_scaling = nn.Identity()
            self.audio_scaling = nn.Identity()
    
    def forward(
        self,
        features: Dict[str, torch.Tensor],
        modality_presence: Optional[Dict[str, bool]] = None,
    ) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­ï¼šå¯¹ç‰¹å¾è¿›è¡ŒL2å½’ä¸€åŒ–å’Œæ¸©åº¦ç¼©æ”¾
        
        Args:
            features: æŠ•å½±åçš„ç‰¹å¾å­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸ºç‰¹å¾å¼ é‡
                å½¢çŠ¶ä¸º(B, 512)ï¼Œdtype=float32ï¼ˆåŒ¹é…LLM embeddingç»´åº¦ï¼‰
            modality_presence: æ¨¡æ€å­˜åœ¨æ ‡è®°å­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸ºbool
                å¦‚æœä¸ºNoneï¼Œåˆ™æ ¹æ®featuresä¸­çš„é”®è‡ªåŠ¨æ¨æ–­
        
        Returns:
            åå¤„ç†åçš„ç‰¹å¾å­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼Œå€¼ä¸ºç‰¹å¾å¼ é‡
            å½¢çŠ¶ä¸º(B, 512)ï¼Œå·²L2 normalizeï¼Œdtype=float32ï¼ˆåŒ¹é…LLM embeddingç»´åº¦ï¼‰
            ç¼ºå¤±çš„æ¨¡æ€è¿”å›é›¶å‘é‡
        """
        # å¦‚æœæ²¡æœ‰æä¾›modality_presenceï¼Œæ ¹æ®featuresè‡ªåŠ¨æ¨æ–­
        if modality_presence is None:
            modality_presence = {
                modality.value: modality.value in features and features[modality.value] is not None
                for modality in [Modality.TEXT, Modality.IMAGE, Modality.AUDIO]
            }
        
        outputs = {}
        
        for modality in [Modality.TEXT, Modality.IMAGE, Modality.AUDIO]:
            modality_key = modality.value
            # ğŸ”§ ä¿®å¤ï¼šå¦‚æœmodality_presenceä¸ºFalseï¼Œç›´æ¥è¿”å›é›¶å‘é‡ï¼ˆä¸å½’ä¸€åŒ–ï¼‰
            if not modality_presence.get(modality_key, False):
                # æ¨¡æ€ä¸å­˜åœ¨ï¼Œè¿”å›é›¶å‘é‡ï¼ˆä¸å½’ä¸€åŒ–ï¼‰
                device = _get_device_from_features(features)
                batch_size = next(iter(features.values())).shape[0] if features else 1
                output_dim = next(iter(features.values())).shape[1] if features else 512
                outputs[modality_key] = torch.zeros(
                    batch_size, output_dim, device=device, dtype=torch.float32
                )
            elif modality_key in features and features[modality_key] is not None:
                x = features[modality_key]
                
                # ğŸ”§ ä¿®å¤ï¼šL2å½’ä¸€åŒ–ï¼ˆNormalizeç±»å·²å¤„ç†é›¶å‘é‡ï¼‰
                x = self.normalize(x)
                outputs[modality_key] = x
            else:
                # æ¨¡æ€å­˜åœ¨ä½†ç‰¹å¾ä¸ºNoneï¼Œè¿”å›é›¶å‘é‡ï¼ˆä¸å½’ä¸€åŒ–ï¼‰
                device = _get_device_from_features(features)
                batch_size = next(iter(features.values())).shape[0] if features else 1
                output_dim = next(iter(features.values())).shape[1] if features else 512
                outputs[modality_key] = torch.zeros(
                    batch_size, output_dim, device=device, dtype=torch.float32
                )
        
        return outputs
    
    def get_logit_scales(self) -> Dict[str, torch.Tensor]:
        """
        è·å–å„æ¨¡æ€çš„logit scaleå€¼ï¼ˆç”¨äºæŸå¤±è®¡ç®—ï¼‰
        
        Returns:
            logit scaleå­—å…¸ï¼Œé”®ä¸ºæ¨¡æ€åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼Œå€¼ä¸ºlogit scaleå¼ é‡
        """
        if not self.use_temperature_scaling:
            return {}
        
        return {
            Modality.TEXT.value: self.text_scaling.logit_scale.exp(),
            Modality.IMAGE.value: self.image_scaling.logit_scale.exp(),
            Modality.AUDIO.value: self.audio_scaling.logit_scale.exp(),
        }

